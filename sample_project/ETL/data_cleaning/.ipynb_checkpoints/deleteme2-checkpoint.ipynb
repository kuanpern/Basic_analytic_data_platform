{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "input_datadir = '../../data/dump/'\n",
    "db_path = '/home/tankp/basic_data_platform/data/sg_weather.db'\n",
    "dt_cut = 36*86400 # 36 hour expiry time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "curtime = time.time()*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files\n",
    "files = glob.glob(input_datadir+'/rainfall/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select relevant files \n",
    "sel_files = []\n",
    "for filename in files:\n",
    "    _timestamp = os.path.basename(filename).split('-')[0]\n",
    "    _timestamp = int(_timestamp)\n",
    "    dt = (curtime - _timestamp) / 1000.\n",
    "    if dt < dt_cut:\n",
    "        sel_files.append(filename)\n",
    "    # end if\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/dump//rainfall/1541136275491-rainfall.json',\n",
       " '../../data/dump//rainfall/1541137170736-rainfall.json']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info('%d files selected' % (len(sel_files),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename):\n",
    "    with open(filename) as fin:\n",
    "        data = json.load(fin)\n",
    "    # end with\n",
    "\n",
    "    # get station id dictionary\n",
    "    station_ids = {}\n",
    "    for dat in data['metadata']['stations']:\n",
    "        #at = dat[0]\n",
    "        station_ids[dat['device_id']] = dat['name']\n",
    "    # end for\n",
    "\n",
    "    item_data = data['items'][0]\n",
    "    # get datetime\n",
    "    _date = str(item_data['timestamp'].split('T')[0])\n",
    "\n",
    "    recs = []\n",
    "    for dat in item_data['readings']:\n",
    "        # get station\n",
    "        _station = station_ids[dat['station_id']]\n",
    "        # get value\n",
    "        value = dat['value']\n",
    "        # make to dict\n",
    "        _item = {\n",
    "          'Station': _station, \n",
    "          'Datetime': _date,\n",
    "          'Daily Rainfall Total (mm)': value, \n",
    "        } # end item\n",
    "\n",
    "        recs.append(_item)\n",
    "    # end for\n",
    "\n",
    "    return recs\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recs = []\n",
    "for filename in sel_files:\n",
    "    Recs.extend(extract_data(filename))\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe\n",
    "df_content = pd.DataFrame(Recs)\n",
    "\n",
    "keys = ['Station', 'Datetime', 'Daily Rainfall Total (mm)', \n",
    "        'Highest 30 Min Rainfall (mm)', 'Highest 60 Min Rainfall (mm)', \n",
    "        'Highest 120 Min Rainfall (mm)', 'Mean Temperature (C)', \n",
    "        'Maximum Temperature (C)', 'Minimum Temperature (C)', \n",
    "        'Mean Wind Speed (km/h)', 'Max Wind Speed (km/h)']\n",
    "df = pd.DataFrame([], columns=keys)\n",
    "df = df.merge(df_content, how='outer')\n",
    "df = df[keys]\n",
    "\n",
    "# drop duplicates\n",
    "df = df.drop_duplicates(subset=['Station', 'Datetime'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update to database\n",
    "#logger.info('connecting database')\n",
    "engine = sqlalchemy.create_engine('sqlite:///'+db_path)\n",
    "df.to_sql('raw_data', con=engine, if_exists='replace', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
